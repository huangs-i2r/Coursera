In this video we will cover 1d tensors, and teach you about some of the common operations that you will use with tensors when building a neural network, pre-processing your data or analyzing your results. Let’s get started! Tensors are arrays that are the building blocks of a neural network. In this video, we will learn the basics of 1-D tensors such as Types, Indexing and Slicing, Basic Operations, Universal Functions Let’s start by understanding what a 1 D tensor is A 0-d tensor is just a number, 1-D tensor is an array of numbers. It could be: A row in a data database, A vector, Time series A tensor contains elements of a single data type. The tensor type is the type of tensor. When we are dealing with real numbers, the tensor type could either be a float tensor or a double tensor. When we are dealing with unsigned integers that are used in 8 bit images, the tensor type is a byte tensor. Thus, we see we have a variety of different tensor types depending upon the data type of the elements in the tensor We can create a tensor in the following manner: First, we import torch. Next, we create a python list with the following elements 7,4,3,2,6. We then cast this list to a pytorch tensor using the constructor for tensors. And that’s it! It’s that simple to create a tensor in pytorch We can access the data via an index in the tensor. As with a lists, we can access each element with an integer and a square bracket. We can use the data attribute dtype to find the type of data that is stored within the tensor We can use the method type to find the type of the tensor. In this example, we create a float tensor, as the elements in the list are floats. We can use the data attribute dtype to find the type of data that is stored within the Tensor We can use the method type to find the type of the tensor. We can also specify the datatype of a tensor with the constructor. We can specify the data type using the parameter d type Even though the list contains floats, the dtype of the tensor is int 32. We can also explicitly create a tensor of a specific type, in this example we create a float tensor explicitly using the FloatTensor method Now, let’s check the type of tensor. We see the type of the tensor is a float tensor. When we print out a, we can see the decimals were added to the numbers in the tensor. We can also change the type of the tensor. Consider the following tensor of long type. We can convert the type of the tensor to float using the type method, passing in the argument torch.FloatTensor We can verify the type of the tensor has changed We can cast the following list to a tensor. The method size gives us the number of elements in the tensor. As there a 5 elements the result is 5. The attribute “ndimension” represents the number of dimensions or the rank of the tensor. In this case rank of the tensor is one In many cases, you will require 2-D tensors as inputs to your neural networks. (click 1) Here we have a pytorch tensor with 5 elements in it. The dimension of this tensor is 1. We will convert this tensor into a 2-D tensor using the view method in pytorch (click 2,3) The first argument of the view method represents the number of rows in this case 5 and the second element represents the number of columns, in this case, 1. (click 4) if we didn't know that the original tensor had 5 elements in it, we could use a value of -1 for the first argument and pytorch will infer the number of rows in the new tensor for us Thus, if we now check the dimension of the a_col tensor using the ndimension method in pytorch, we will see it has a dimension of 2 Thus, you might need to convert your 1-D tensors to 2-D tensors before you could use them as inputs Here we have a pytorch tensor with 5 elements in it. The dimension of this tensor is 1. We will convert this tensor into a 2-D tensor using the view method in pytorch. The first argument of the view method represents the number of rows in this case 5 and the second element represents the number of columns, in this case, 1. If we didn't know that the original tensor had 5 elements in it, we could use a value of -1 for the first argument and pytorch will infer the number of rows in the new tensor for us. Thus, if we now check the dimension of the a_col tensor using the ndimension method in pytorch, we will see it has a dimension of 2 In this example, the tensor has 6 elements in it as before we can reshape the tensor using the view method, as there is 6 elements in the original tensor, we pass 6 as the first argument to the view method for creating 6 rows and 1 as the second argument to create one column. Similarly, we could have used a -1 instead of 6 It's not difficult to convert PyTorch tensors to numpy arrays and Python lists and then convert them back It's not difficult to convert PyTorch tensors to numpy arrays and Python lists and then convert them back. This gives PyTorch the ability to work within the python ecosystem Many Python libraries use numpy arrays. Consider the following numpy array [click 2] we can convert a numpy array to a torch tensor using the function “from numpy” [click 3] we can convert the torch tensor back to numpy array using the method numpy [click 4] let's represent numpy_array with the blue box and [click 5] the torch tensor with a red box [click 6] and back_to_numpy with a green box [click 7] back_to_numpy points to the variable torch_tensor [click 8] the variable torch_tensor points to the variable numpy_array , therefore if you change the variable numpy_array both torch_tensor and back_to_numpy will change. You will see an example of this in the lab Many Python libraries use numpy arrays. Consider the following bumpy array. We can convert a numpy array to a torch tensor using the function “from numpy”. We can convert the torch tensor back to numpy array using the method numpy Let's represent numpy_array with the blue box and the torch tensor with a red box and back_to_numpy with a green box. Back_to_numpy points to the variable torch_tensor. The variable torch_tensor points to the variable numpy_array, therefore if you change the variable numpy_array both torch_tensor and back_to_numpy will change. You will see an example of this in the lab We can convert a pandas series to a tensor in a similar manner We simply use the attribute “values” to convert the series to a numpy array We then use the function from numpy to convert it to a tensor. We can use the method “to_list” to return a list from a tensor Individual values of a tensor are also tensors. Consider the tensor new_tensor. The first element of new_tensor is a tensor and is given by the following Similarly the second element of new_tensor is also a tensor and is given by the following In many cases, we would like to work a Python number instead of tensors. For this, we can use the method “item” to return a number For example, we can return the number of the first value. Similarly, we can do it for the second value Lets review some Indexing and Slicing methods that you can use to access a particular value or set of values stored in a tensor Consider the following tensor We can change the first element of the tensor to 100 as follows. The tensors first value is now 100 We can change the 5-th element of the tensor as follows. The fifth element is now 0 We can slice pytorch tensors just like python lists The elements of the array correspond to the following index. We can select the elements from 1 to 3 and assign it to a new Torch tensor 'd' as follows: The elements in "d" correspond to the following indexes, and similar to lists we do not count the element corresponding to the last index. We can assign indexes in a tensor to new values as follows The tensor 'c' now has new values Pytorch makes it easy to do many operations that are commonly performed in neural networks. Lets review some of these operations on 1 dimensional tensors. We will look at many of the operations in the context of Euclidian vectors to make things more interesting. Vector addition is a widely used operation, consider the vector "u" with two elements or components; the components are distinguished by the different colors. Similarly consider the vector 'v' with two components. In vector addition, we create a new vector, in this case we call it "z" The first component of z is the addition of the first component of vectors u and v. Similarly the second component is the sum of the second components of u and v. This new vector z is now a linear combination of the vector ‘u’ and ‘v’ To perform vector addition in pytorch, we simply do it by defining the the tensors u and v and then adding them up. It should be noted that the tensors should be of the same type. Vector multiplication with a scalar is another commonly performed operation. Consider the vector "y", each component is specified by a different color. We simply multiply the vector by a scaler value, in this case, 2. Each component of the vector is multiplied by 2, Thus, in this case, each component is doubled. In pytorch we can simply multiply a tensor by a single line of code as follows. Hadamard Product is another widely used operation Consider the following tensors or vectors. The result of the Hadamard Product of u and v is a new vector z. The first component of z is the product of the first element of u and v. Similarly, the second component is the product of the second element of u and v. The resultant vector consists of the entry wise product of u and v. In Pytorch, we can also perform Hadamard product with just 1 line of code and assign it to a variable z. The dot product is another widely used operation used in neural networks. Consider the vectors u and v. The dot product is a single number that represents how similar the two vectors are. We multiply the first component from v and u. We then multiply the second component and add the result together. The result is a number that represents how similar the two vectors are. Just a note we will represent the dot product as follows. We can also perform dot product using the pythorch function “dot” and assign it the the tensor “result” as follows. Consider a tensor u The tensor contains the following elements. If we add a scalar value to the tensor, Pytorch will add that value to each element in the tensor. This property is known as broadcasting. We can also apply functions to torch tensors. We will teach you how to do so, but we will not cover in-place operations Consider the tensor "a“, we can calculate the mean or average value of all the elements in 'a' using the method "mean“. This corresponds to the average of all the elements. In this case the result is zero. There are many other functions for example, consider the tensor "b“ We can find the maximum value using the method max We see the largest value is 5, therefore the method max returns a 5. We can use torch to create functions that map tensor to new torch tensors. Let's implement some code on the left side of the screen and use the right side of the screen to demonstrate what's going on with vectors. We can access the value of pie in numpy as follows (click 2) we can create the following torch tensor in Radians. (click 3) this array corresponds to the following vector (click 4) we can apply the function "sine" to the tensor x and assign the values to the tensor y; this applies the sine function to each element in the tensor (click 5) this corresponds to applying the sine function to each component of the vector (click 6) the result is a new tensor y where each value corresponds to a sine function being applied to each element in the tensor x We can access the value of pie in numpy as follows. We can create the following torch tensor in Radians. This array corresponds to the following vector We can apply the function "sine" to the tensor x and assign the values to the tensor y; this applies the sine function to each element in the tensor This corresponds to applying the sine function to each component of the vector The result is a new tensor y where each value corresponds to a sine function being applied to each element in the tensor x. A useful function for plotting mathematical functions is "linespace". Linespace returns evenly spaced numbers over a specified interval. We specify the starting point of the sequence, the ending point of the sequence, the parameter ”steps" indicates the number of samples to generate, in this case, 5. (click 6) the space between samples is 1 If we change the parameter num to 9, we get 9 evenly spaced numbers over the interval from -2 to 2. The result is the difference between subsequent samples is 0.5 as compared to the example before. We can use the function line space to generate 100 evenly spaced samples from the interval 0 to 2 pi. We can use the Pytorch function sine to map the tensor x to a new tensor y. We can import the library pyplot as plt to help us plot the function As we are using a Jupiter notebook, we use the command "matplotlib inline" to display the plot. The following command plots a graph. The first input corresponds to the x value. We have to convert the tensor to a numpy array using the method numpy. The second input corresponds to the values for the vertical or y-axis. We convert the values. Similarly, we have to convert it to a numpy array using the method numpy
