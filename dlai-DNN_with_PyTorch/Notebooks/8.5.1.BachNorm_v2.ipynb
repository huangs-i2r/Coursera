{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://cocl.us/pytorch_link_top\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/Pytochtop.png\" width=\"750\" alt=\"IBM Product \" />\n",
    "</a> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/cc-logo-square.png\" width=\"200\" alt=\"cognitiveclass.ai logo\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Batch Normalization with the MNIST Dataset</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n",
    "In this lab, you will build a Neural Network using Batch Normalization and compare it to a Neural Network that does not use Batch Normalization. You will use the MNIST dataset to test your network. \n",
    "\n",
    "<ul>\n",
    "<li><a href=\"#Train_Func\">Neural Network Module and Training Function</a></li>\n",
    "<li><a href=\"#Makeup_Data\">Load Data </a></li>\n",
    "<li><a href=\"#NN\">Define Several Neural Networks, Criterion function, Optimizer</a></li>\n",
    "<li><a href=\"#Train\">Train Neural Network using Batch Normalization and no Batch Normalization</a></li>\n",
    "<li><a href=\"#Result\">Analyze Results</a></li>\n",
    "</ul>\n",
    "<p>Estimated Time Needed: <strong>25 min</strong></p>\n",
    "</div>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preparation</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need the following libraries:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f21880f0190>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the libraries will be used for this lab.\n",
    "\n",
    "# Using the following line code to install the torchvision library\n",
    "# !conda install -y torchvision\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Train_Func\">Neural Network Module and Training Function</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the neural network module or class "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Neural Network Module with two hidden layers using Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Neural Network Model using Batch Normalization\n",
    "\n",
    "class NetBatchNorm(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, in_size, n_hidden1, n_hidden2, out_size):\n",
    "        super(NetBatchNorm, self).__init__()\n",
    "        self.linear1 = nn.Linear(in_size, n_hidden1)\n",
    "        self.linear2 = nn.Linear(n_hidden1, n_hidden2)\n",
    "        self.linear3 = nn.Linear(n_hidden2, out_size)\n",
    "        self.bn1 = nn.BatchNorm1d(n_hidden1)\n",
    "        self.bn2 = nn.BatchNorm1d(n_hidden2)\n",
    "        \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        x = self.bn1(torch.sigmoid(self.linear1(x)))\n",
    "        x = self.bn2(torch.sigmoid(self.linear2(x)))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "    \n",
    "    # Activations, to analyze results \n",
    "    def activation(self, x):\n",
    "        out = []\n",
    "        z1 = self.bn1(self.linear1(x))\n",
    "        out.append(z1.detach().numpy().reshape(-1))\n",
    "        a1 = torch.sigmoid(z1)\n",
    "        out.append(a1.detach().numpy().reshape(-1).reshape(-1))\n",
    "        z2 = self.bn2(self.linear2(a1))\n",
    "        out.append(z2.detach().numpy().reshape(-1))\n",
    "        a2 = torch.sigmoid(z2)\n",
    "        out.append(a2.detach().numpy().reshape(-1))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network Module with two hidden layers with out Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Net for Neural Network Model\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, in_size, n_hidden1, n_hidden2, out_size):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(in_size, n_hidden1)\n",
    "        self.linear2 = nn.Linear(n_hidden1, n_hidden2)\n",
    "        self.linear3 = nn.Linear(n_hidden2, out_size)\n",
    "    \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.linear1(x))\n",
    "        x = torch.sigmoid(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "    \n",
    "    # Activations, to analyze results \n",
    "    def activation(self, x):\n",
    "        out = []\n",
    "        z1 = self.linear1(x)\n",
    "        out.append(z1.detach().numpy().reshape(-1))\n",
    "        a1 = torch.sigmoid(z1)\n",
    "        out.append(a1.detach().numpy().reshape(-1).reshape(-1))\n",
    "        z2 = self.linear2(a1)\n",
    "        out.append(z2.detach().numpy().reshape(-1))\n",
    "        a2 = torch.sigmoid(z2)\n",
    "        out.append(a2.detach().numpy().reshape(-1))\n",
    "        return out \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to train the model. In this case the function returns a Python dictionary to store the training loss and accuracy on the validation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to train model\n",
    "\n",
    "def train(model, criterion, train_loader, validation_loader, optimizer, epochs=100):\n",
    "    i = 0\n",
    "    useful_stuff = {'training_loss':[], 'validation_accuracy':[]}  \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for i, (x, y) in enumerate(train_loader):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            z = model(x.view(-1, 28 * 28))\n",
    "            loss = criterion(z, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            useful_stuff['training_loss'].append(loss.data.item())\n",
    "            \n",
    "        correct = 0\n",
    "        for x, y in validation_loader:\n",
    "            model.eval()\n",
    "            yhat = model(x.view(-1, 28 * 28))\n",
    "            _, label = torch.max(yhat, 1)\n",
    "            correct += (label == y).sum().item()\n",
    "            \n",
    "        accuracy = 100 * (correct / len(validation_dataset))\n",
    "        useful_stuff['validation_accuracy'].append(accuracy)\n",
    "    \n",
    "    return useful_stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Makeup_Data\">Make Some Data</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training dataset by setting the parameters <code>train </code> to <code>True</code> and convert it to a tensor  by placing a transform object int the argument <code>transform</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the train dataset\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the validating dataset by setting the parameters train  <code>False</code> and convert it to a tensor by placing a transform object into the argument <code>transform</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the train dataset\n",
    "\n",
    "validation_dataset = dsets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create the training-data loader and the validation-data loader object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data Loader for both train and validating\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=2000, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=5000, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref3\"></a>\n",
    "<h2 align=center>Define Neural Network, Criterion function, Optimizer and Train the  Model  </h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the criterion function  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the criterion function\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables for Neural Network Shape <code> hidden_dim</code> used for number of neurons in both hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters\n",
    "\n",
    "input_dim = 28 * 28\n",
    "hidden_dim = 100\n",
    "output_dim = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Train\">Train Neural Network using Batch Normalization and no Batch Normalization </h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Neural Network using  Batch Normalization :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model, optimizer and train the model\n",
    "\n",
    "model_norm  = NetBatchNorm(input_dim, hidden_dim, hidden_dim, output_dim)\n",
    "optimizer = torch.optim.Adam(model_norm.parameters(), lr = 0.1)\n",
    "training_results_Norm=train(model_norm , criterion, train_loader, validation_loader, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Neural Network with no Batch Normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model without Batch Normalization, optimizer and train the model\n",
    "\n",
    "model = Net(input_dim, hidden_dim, hidden_dim, output_dim)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.1)\n",
    "training_results = train(model, criterion, train_loader, validation_loader, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Result\">Analyze Results</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the histograms of the activation for the first layer of the first sample, for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "model_norm.eval()\n",
    "out=model.activation(validation_dataset[0][0].reshape(-1,28*28))\n",
    "plt.hist(out[2],label='model with no batch normalization' )\n",
    "out_norm=model_norm.activation(validation_dataset[0][0].reshape(-1,28*28))\n",
    "plt.hist(out_norm[2],label='model with normalization')\n",
    "plt.xlabel(\"activation \")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the activations with Batch Normalization are zero centred and have a smaller variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the training loss for each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the diagram to show the loss\n",
    "\n",
    "plt.plot(training_results['training_loss'], label='No Batch Normalization')\n",
    "plt.plot(training_results_Norm['training_loss'], label='Batch Normalization')\n",
    "plt.ylabel('Cost')\n",
    "plt.xlabel('iterations ')   \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the validating accuracy for each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the diagram to show the accuracy\n",
    "\n",
    "plt.plot(training_results['validation_accuracy'],label='No Batch Normalization')\n",
    "plt.plot(training_results_Norm['validation_accuracy'],label='Batch Normalization')\n",
    "plt.ylabel('validation accuracy')\n",
    "plt.xlabel('epochs ')   \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://cocl.us/pytorch_link_bottom\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/notebook_bottom%20.png\" width=\"750\" alt=\"PyTorch Bottom\" />\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>About the Authors:</h2> \n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other contributors: <a href=\"https://www.linkedin.com/in/michelleccarey/\">Michelle Carey</a>, <a href=\"www.linkedin.com/in/jiahui-mavis-zhou-a4537814a\">Mavis Zhou</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; 2018 <a href=\"cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu\">cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\">MIT License</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
