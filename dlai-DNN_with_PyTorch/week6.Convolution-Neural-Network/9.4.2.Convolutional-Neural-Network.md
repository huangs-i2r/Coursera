In this video we see how to build a CNN for MNIST, to make things faster in the lab we will use an image size of 16 by 16. This is an image we will use to understand the shape of our CNN; it is similar to our previous example except we will have 16 output channels for our first convolution layer. For our second convolution layer, we will have 16 inputs and 32 outputs. The input to the final layer will be a different shape. As there are ten layers for MNIST, we will have ten output neurons. Let us review the constructor and forward method. We will use the same structure as our simple cnn, but we will have more channels in each layer. We produce a 2d convolution object cnn1, with a kernel size of 5, padding of 2 and 16 output channels. We will add a max pooling object ‘maxpool1; with a kernel size of 2 and using the default stride. We will apply the activation in the forward step. We then add the second convolution layer cnn2, with 16 input channels and 32 output channels, kernel size of 5, stride size one and padding of 2. We will add a second max pooling layer maxpool2 we then add a final out put linear layer. Let's examine the shape of the output layer. The output if the max pooling will be 4 by 4, as a result we are going to have 4 by 4 inputs. We also have the output channels. We have 32 output channels each channel is 4x4 for a total of 16 elements. As there are 32 channels multiplied by 16 we have a total of 512 elements. We flatten or reshape the tensor to have 512 outputs as a result each neuron will have 512 input dimensions, as we have 10 classes we have 10 neurons. Let's see the forward step. We apply the first 2d convolution object cnn1 followed by activation function and max pooling, we then apply the second convolution layer cnn2, followed by the second activation function and max pooling, we take the output channels. We flatten or reshape the output channels, we then apply the output layer. And that’s it! See the lab for the training process and other details.
