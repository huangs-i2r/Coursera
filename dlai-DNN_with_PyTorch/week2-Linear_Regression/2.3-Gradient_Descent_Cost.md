#### Gradient Descent

Gradient descent is a method to find the minimum of a function, it can be applied to functions with multiple dimensions. But let's look at the example of just one dimension. In this video we will review: What's Gradient Descent, Problems with the Learning Rate, When to Stop Gradient Descent. What's Gradient Descent. Gradient descent is a method to find the minimum of a function. Consider the loss function, if we start off with a random guess for the slope parameter, we use the super script to indicate the guess number In this case it is our first guess so it is zero, we have to move our guess in the positive direction. We can move the slope in that direction by adding a positive number, examining the sign of of the derivative it is the opposite sign of the number. Therefore we can add a number proportional to the negative of the slope. Subtracting the derivative works if we are on the other side of the minimum. In this case, we would like to move in the negative direction We can move the parameter value to the negative direction by adding a negative number to the parameter. Examining the sine of the derivative, it is the opposite sine of the number. Therefore we can add an amount proportional to the negative of the derivative. In Gradient descent we iteratively calculate this equation, we start off with a guess, we update the parameter by adding a value proportional to the derivative. We update the parameter again We can express the process as follows the parameter eta is the learning rate and tells us how much we need to jump. Let us clarify the process with an example. We start off with a guess of -4. The value for the derivative at -4 is -112. We will use the following value for the learning rate. We calculate the first iteration, the value of the parameter for the first iteration is -1.20. The value for this parameter has a smaller loss, we can see the loss is lower after the first iteration. For the next iterations, we use the previous parameter estimate of -1.2. We update the parameter value using the update rule The value for the parameter is now -0.64, the loss function is closer to the minimum, the loss value continues to get smaller. Let's see problems with the learning rate. If we chose a learning rate thatâ€™s toobig, sometimes we miss the minimum. Let's say we use a learning rate of 1 over 5, we update the parameter value using the update rule. The value for the parameter is now -3.28, the loss function now has a higher value, now the loss value gets larger. Sometimes we can set the learning rate too small, let's see what happens when we set the learning rate to 1/240. For every iteration the value of the parameter hardly changes. In this case it will take a lot of iterations to reach the minimum value. We will learn how to select the learning rate. There are several ways to stop the process of gradient descent. Let's go over a few popular ways when to stop Gradient Descent. We can run gradient descent, for a set number of iterations is a popular way, in this case we run it for 3 iterations. But for the final iteration we miss the minimum. Another method to stop gradient descent is to see if the loss starts increasing, Let's record a few iterations of gradient descent and record the results in the table. For the first value, the loss is 250. We calculate the first iteration, we see the loss for this iteration is 150 less than the previous iteration. For the second iteration, the loss is also decreasing, we repeat the process. Examining the table we see the loss is 50 and still decreasing, so we keep going. The loss is now 100, this value is larger than 50 so we stop, We use the value of the parameter corresponding to loss of 50, the value is approximately - 2.5. You will learn more about gradient descent through out the course.

#### Cost

In this section we will review the cost function. When using the cost instead of determining the value of the parameter for one sample, we select parameters that minimize the loss value for multiple points. We can visualize it with little squares whose area is the same as the error. Sometimes we divide the error or loss by the number of samples in this case three. In this course we will use both the total as well as the average Pictorially we are just finding the average area of each square. The sum of the Loss is called the cost. Sometimes we will refer to is the total or average loss. As much of the PyTorch documentation refer to it as the loss function, we will use the symbol L. Symbolically the cost function looks like this, it is a function of the slope The slope controls the relationship between x and y, the bias, controls the horizontal offset. We can perform gradient descent on the cost function as, the derivative of the cost function is. Let's see what happens when we take a few iterations of gradient descent with just the slope. Let's consider the example where we just examine the slope, taking the derivative we get the following expression, the actual line or data space is shown on the top right, the cost function with respect to the slope is on the bottom. Examining the value of the derivative we see its negative, as both samples produce the same negative numbers and we are adding them the magnitude is quite large. We see the parameters is updated by adding a large positive value, the loss is updated, and the jump is relatively large. As we update the parameter the predicted line gets closer to the data points. In this example, the data point is on the other side of the line. If we take the derivative we see the result is positive. As both samples produce the same positive numbers and we are adding them, the magnitude is quite large. Performing the update step we add a large negative number, therefore the parameter value decreases by a large amount. After the parameter value is updated the line gets closer In this example one data point is on one side of the line and the other data point is on the other As one value is positive and the second is negative the derivative is near zero. All the samples in the training set are called a Batch. As we use all the samples, we sometimes call gradient descent batch gradient descent Here is an example where the batch size is three. We use all the samples to calculate the loss, then find the derivative.
